{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install telethon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Telegram imports\n",
    "from telethon.sync import TelegramClient\n",
    "\n",
    "# Setup / change only the first time you use it\n",
    "username = 'roskameyka'  # Your Telegram account username (just 'abc123', not '@')\n",
    "phone = '+31616045195'  # Your Telegram account phone number (ex: '+5511999999999')\n",
    "api_id = '15331462'  # Your API ID, it can be only generated from https://my.telegram.org/apps\n",
    "api_hash = '0ea1021965ce6dd5aa5370b94abc9c2d'  # Your API hash, also from https://my.telegram.org/apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup / change every time to define scraping parameters\n",
    "channels = [\n",
    "    '@moscowmap', #Moscow\n",
    "    '@moscowach', #Moscow\n",
    "    '@piterach' #Saint Petersburg\n",
    "    '@ngs_news', #Novosibirsk\n",
    "    '@novostisochi', #Sochi\n",
    "    '@RU66RU', #Yekaterinburg\n",
    "    '@ngs24_krsk', #Krasnoyarsk\n",
    "    '@rian_ru' #National\n",
    "]\n",
    "# Here you put the name of the channel or group that you want to scrape\n",
    "# As an example, play: '@LulanoTelegram' or 'https://t.me/LulanoTelegram'\n",
    "# Do not use: 'https://web.telegram.org/a/#-1001249230829' or '-1001249230829'\n",
    "\n",
    "d_min = 1  # Start day (inclusive)\n",
    "m_min = 1  # Start month\n",
    "y_min = 2000  # Start year\n",
    "d_max = 19  # End day (exclusive)\n",
    "m_max = 11  # End month\n",
    "y_max = 2024  # End year\n",
    "key_search = 'дтп'  # Keyword to search, leave empty if not needed\n",
    "max_t_index = 10  # Maximum number of messages to scrape\n",
    "time_limit = 6 * 60 * 60  # Timeout in hours (*seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []  # List to store scraped data\n",
    "t_index = 0  # Tracker for the number of messages processed\n",
    "start_time = time.time()  # Record the start time for the scraping session\n",
    "\n",
    "# Function to remove invalid XML characters from text\n",
    "def remove_unsupported_characters(text):\n",
    "    valid_xml_chars = (\n",
    "        \"[^\\u0009\\u000A\\u000D\\u0020-\\uD7FF\\uE000-\\uFFFD\"\n",
    "        \"\\U00010000-\\U0010FFFF]\"\n",
    "    )\n",
    "    cleaned_text = re.sub(valid_xml_chars, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Function to format time in days, hours, minutes, and seconds\n",
    "def format_time(seconds):\n",
    "    days = seconds // 86400\n",
    "    hours = (seconds % 86400) // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f'{int(days):02}:{int(hours):02}:{int(minutes):02}:{int(seconds):02}'\n",
    "\n",
    "# Function to print progress of the scraping process\n",
    "def print_progress(t_index, message_id, start_time, max_t_index):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    current_progress = t_index / (t_index + message_id) if (t_index + message_id) <= max_t_index else t_index / max_t_index\n",
    "    percentage = current_progress * 100\n",
    "    estimated_total_time = elapsed_time / current_progress\n",
    "    remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "    elapsed_time_str = format_time(elapsed_time)\n",
    "    remaining_time_str = format_time(remaining_time)\n",
    "\n",
    "    print(f'Progress: {percentage:.2f}% | Elapsed Time: {elapsed_time_str} | Remaining Time: {remaining_time_str}')\n",
    "\n",
    "# Scraping process\n",
    "for channel in channels:\n",
    "    if t_index >= max_t_index:\n",
    "        break\n",
    "\n",
    "    if time.time() - start_time > time_limit:\n",
    "        break\n",
    "\n",
    "    loop_start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        c_index = 0\n",
    "        async with TelegramClient(username, api_id, api_hash) as client:\n",
    "            async for message in client.iter_messages(channel, search=key_search):\n",
    "                try:\n",
    "                    if datetime(y_min, m_min, d_min, tzinfo=timezone.utc) < message.date <= datetime(y_max, m_max, d_max, tzinfo=timezone.utc):\n",
    "\n",
    "                        # Process comments of the message\n",
    "                        comments_list = []\n",
    "                        try:\n",
    "                            async for comment_message in client.iter_messages(channel, reply_to=message.id):\n",
    "                                comment_text = comment_message.text.replace(\"'\", '\"')\n",
    "\n",
    "                                comment_media = 'True' if comment_message.media else 'False'\n",
    "\n",
    "                                comment_emoji_string = ''\n",
    "                                if comment_message.reactions:\n",
    "                                    for reaction_count in comment_message.reactions.results:\n",
    "                                        emoji = reaction_count.reaction.emoticon\n",
    "                                        count = str(reaction_count.count)\n",
    "                                        comment_emoji_string += emoji + \" \" + count + \" \"\n",
    "\n",
    "                                comment_date_time = comment_message.date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                                comments_list.append({\n",
    "                                    'Type': 'comment',\n",
    "                                    'Comment Group': channel,\n",
    "                                    'Comment Author ID': comment_message.sender_id,\n",
    "                                    'Comment Content': comment_text,\n",
    "                                    'Comment Date': comment_date_time,\n",
    "                                    'Comment Message ID': comment_message.id,\n",
    "                                    'Comment Author': comment_message.post_author,\n",
    "                                    'Comment Views': comment_message.views,\n",
    "                                    'Comment Reactions': comment_emoji_string,\n",
    "                                    'Comment Shares': comment_message.forwards,\n",
    "                                    'Comment Media': comment_media,\n",
    "                                    'Comment Url': f'https://t.me/{channel}/{message.id}?comment={comment_message.id}'.replace('@', ''),\n",
    "                                })\n",
    "                        except Exception as e:\n",
    "                            comments_list = []\n",
    "                            print(f'Error processing comments: {e}')\n",
    "\n",
    "                        # Process the main message\n",
    "                        media = 'True' if message.media else 'False'\n",
    "\n",
    "                        emoji_string = ''\n",
    "                        if message.reactions:\n",
    "                            for reaction_count in message.reactions.results:\n",
    "                                emoji = reaction_count.reaction.emoticon\n",
    "                                count = str(reaction_count.count)\n",
    "                                emoji_string += emoji + \" \" + count + \" \"\n",
    "\n",
    "                        date_time = message.date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        cleaned_content = remove_unsupported_characters(message.text)\n",
    "                        cleaned_comments_list = remove_unsupported_characters(json.dumps(comments_list))\n",
    "\n",
    "                        data.append({\n",
    "                            'Type': 'text',\n",
    "                            'Group': channel,\n",
    "                            'Author ID': message.sender_id,\n",
    "                            'Content': cleaned_content,\n",
    "                            'Date': date_time,\n",
    "                            'Message ID': message.id,\n",
    "                            'Author': message.post_author,\n",
    "                            'Views': message.views,\n",
    "                            'Reactions': emoji_string,\n",
    "                            'Shares': message.forwards,\n",
    "                            'Media': media,\n",
    "                            'Url': f'https://t.me/{channel}/{message.id}'.replace('@', ''),\n",
    "                            'Comments List': cleaned_comments_list,\n",
    "                        })\n",
    "\n",
    "                        c_index += 1\n",
    "                        t_index += 1\n",
    "\n",
    "                        # Print progress\n",
    "                        print(f'{\"-\" * 80}')\n",
    "                        print_progress(t_index, message.id, start_time, max_t_index)\n",
    "                        current_max_id = min(c_index + message.id, max_t_index)\n",
    "                        print(f'From {channel}: {c_index:05} contents of {current_max_id:05}')\n",
    "                        print(f'Id: {message.id:05} / Date: {date_time}')\n",
    "                        print(f'Total: {t_index:05} contents until now')\n",
    "                        print(f'{\"-\" * 80}\\n\\n')\n",
    "\n",
    "                        if t_index >= max_t_index:\n",
    "                            break\n",
    "\n",
    "                        if time.time() - start_time > time_limit:\n",
    "                            break\n",
    "\n",
    "                    elif message.date < datetime(y_min, m_min, d_min, tzinfo=timezone.utc):\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing message: {e}')\n",
    "\n",
    "        print(f'\\n\\n##### {channel} was ok with {c_index:05} posts #####\\n\\n')\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'{channel} error: {e}')\n",
    "\n",
    "    loop_end_time = time.time()\n",
    "    loop_duration = loop_end_time - loop_start_time\n",
    "\n",
    "    if loop_duration < 60:\n",
    "        time.sleep(60 - loop_duration)\n",
    "\n",
    "print(f'\\n{\"-\" * 50}\\n#Concluded! #{t_index:05} posts were scraped!\\n{\"-\" * 50}\\n\\n\\n\\n')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
